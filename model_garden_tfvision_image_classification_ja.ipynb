{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TirJ-SGQseby"
      },
      "source": [
        "# Vertex AI Model Garden の TFVision による画像分類\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fcommunity%2Fmodel_garden%2Fmodel_garden_tfvision_image_classification.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_tfvision_image_classification.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br>\n",
        "      View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## 概要\n",
        "\n",
        "このノートブックでは、Vertex AI Model Garden で [TFVision](https://github.com/tensorflow/models/blob/master/official/vision/MODEL_GARDEN.md) を使用する方法を紹介します。\n",
        "\n",
        "### 目的\n",
        "\n",
        "* 新しいモデルのトレーニング\n",
        "  * 入力データをトレーニングフォーマットに変換する\n",
        "  * 新しいモデルをトレーニングするための [hyperparameter tuning jobs](https://cloud.google.com/vertex-ai/docs/training/hyperparameter-tuning-overview) を作成する\n",
        "  * 最適なモデルを見つけてエクスポートする\n",
        "\n",
        "* トレーニング済みモデルのテスト\n",
        "  * モデルをモデルレジストリにアップロードする\n",
        "  * アップロードしたモデルをデプロイする\n",
        "  * 予測を実行する\n",
        "\n",
        "* リソースのクリーンアップ\n",
        "\n",
        "### コスト\n",
        "\n",
        "このチュートリアルでは、Google Cloud の課金対象となるコンポーネントを使用します。\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "[Vertex AI\n",
        "pricing](https://cloud.google.com/vertex-ai/pricing) と [Cloud Storage\n",
        "pricing](https://cloud.google.com/storage/pricing)について学習し、 [Pricing\n",
        "Calculator](https://cloud.google.com/products/calculator/)\n",
        "を使用して、予測される使用量に基づいてコストの見積もりを生成してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEukV6uRk_S3"
      },
      "source": [
        "## 始める前に"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvqs-ehKlaYh"
      },
      "outputs": [],
      "source": [
        "# @title Google Cloud プロジェクトのセットアップ\n",
        "\n",
        "# @markdown 1. プロジェクトで課金が有効になっていることを確認してください。\n",
        "\n",
        "# @markdown 2. (オプション) 実験出力の保存用に Cloud Storage バケットを作成します。実験環境の BUCKET_URI を設定します。指定された Cloud Storage バケット（`BUCKET_URI`）は、ノートブックが起動されたのと同じリージョンに配置する必要があります。マルチリージョンバケット（例：「us」）は、マルチリージョン範囲でカバーされる単一リージョン（例：「us-central1」）と一致するとは見なされないことに注意してください。設定されていない場合は、代わりに一意の GCS バケットが作成されます。\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "from PIL import Image\n",
        "\n",
        "# デフォルトのクラウドプロジェクトIDを取得します。\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# ジョブ起動のデフォルトリージョンを取得します。\n",
        "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# \"us\"、\"asia\"、または \"europe\" で始まるリージョンのみがサポートされています。\n",
        "REGION_PREFIX = REGION.split(\"-\")[0]\n",
        "assert REGION_PREFIX in (\n",
        "    \"us\",\n",
        "    \"europe\",\n",
        "    \"asia\",\n",
        "), f'{REGION} はサポートされていません。\"us\"、\"asia\"、または \"europe\" で始まる必要があります。'\n",
        "\n",
        "# Vertex AI API と Compute Engine API を有効にします (まだ有効になっていない場合)。\n",
        "! gcloud services enable aiplatform.googleapis.com compute.googleapis.com\n",
        "\n",
        "# 実験アーティファクトを保存するための Cloud Storage バケット。\n",
        "# このノートブックのために一意の GCS バケットが作成されます。独自の GCS バケットを使用する場合は、以下の値を自分で変更してください。\n",
        "now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_URI = \"gs://\"  # @param {type: \"string\"}\n",
        "\n",
        "# ユーザーが指定していない場合は、このノートブックのための一意の GCS バケットを作成します。\n",
        "if BUCKET_URI is None or BUCKET_URI.strip() == \"\" or BUCKET_URI == \"gs://\":\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-tmp-{now}\"\n",
        "    BUCKET_NAME = BUCKET_URI\n",
        "    ! gsutil mb -l {REGION} {BUCKET_URI}\n",
        "else:\n",
        "    assert BUCKET_URI.startswith(\"gs://\"), \"BUCKET_URI は `gs://` で始まる必要があります。\"\n",
        "    BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "    shell_output = ! gsutil ls -Lb {BUCKET_NAME} | grep \"Location constraint:\" | sed \"s/Location constraint://\"\n",
        "    bucket_region = shell_output[0].strip().lower()\n",
        "    if bucket_region != REGION:\n",
        "        raise ValueError(\n",
        "            \"バケットリージョン %s はノートブックリージョン %s と異なります\"\n",
        "            % (bucket_region, REGION)\n",
        "        )\n",
        "\n",
        "print(f\"この GCS バケットを使用します: {BUCKET_URI}\")\n",
        "\n",
        "# デフォルトの SERVICE_ACCOUNT を設定します。\n",
        "SERVICE_ACCOUNT = None\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "print(\"このデフォルトのサービスアカウントを使用します:\", SERVICE_ACCOUNT)\n",
        "\n",
        "# GCS バケットで SERVICE_ACCOUNT に権限を付与します\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.admin $BUCKET_NAME\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user(project_id=PROJECT_ID)\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "CHECKPOINT_BUCKET = os.path.join(BUCKET_URI, \"ckpt\")\n",
        "CONFIG_DIR = os.path.join(BUCKET_URI, \"config\")\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)\n",
        "\n",
        "\n",
        "def upload_config_to_gcs(url):\n",
        "    \"\"\"設定ファイルをGCSにアップロードします。\"\"\"\n",
        "    filename = os.path.basename(url)\n",
        "    destination = os.path.join(CONFIG_DIR, filename)\n",
        "    print(\"コピー\", url, \"から\", destination)\n",
        "    ! wget \"$url\" -O \"$filename\"\n",
        "    ! gsutil cp \"$filename\" \"$destination\"\n",
        "\n",
        "\n",
        "# 各種設定ファイルをGCSにアップロード\n",
        "upload_config_to_gcs(\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/image_classification/imagenet_resnet50_gpu.yaml\"\n",
        ")\n",
        "upload_config_to_gcs(\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/master/official/vision/configs/experiments/image_classification/imagenet_resnetrs50_i160_gpu.yaml\"\n",
        ")\n",
        "upload_config_to_gcs(\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/master/official/projects/maxvit/configs/experiments/maxvit_base_imagenet_gpu.yaml\"\n",
        ")\n",
        "\n",
        "# 定数を定義します。\n",
        "OBJECTIVE = \"icn\" # 目的\n",
        "\n",
        "# データコンバーター定数。\n",
        "DATA_CONVERTER_JOB_PREFIX = \"data_converter\" # データコンバータジョブのプレフィックス\n",
        "DATA_CONVERTER_CONTAINER = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/data-converter\" # データコンバータコンテナ\n",
        "DATA_CONVERTER_MACHINE_TYPE = \"n1-highmem-8\" # データコンバータのマシンタイプ\n",
        "\n",
        "# トレーニング定数。\n",
        "TRAINING_JOB_PREFIX = \"train\" # トレーニングジョブのプレフィックス\n",
        "TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss\" # トレーニングコンテナURI\n",
        "TRAIN_MACHINE_TYPE = \"n1-highmem-16\" # トレーニングのマシンタイプ\n",
        "TRAIN_ACCELERATOR_TYPE = \"NVIDIA_TESLA_P100\" # トレーニングのアクセラレータタイプ\n",
        "TRAIN_NUM_GPU = 1 # トレーニングのGPU数\n",
        "\n",
        "# 評価定数。\n",
        "EVALUATION_METRIC = \"accuracy\" # 評価指標\n",
        "\n",
        "# エクスポート定数。\n",
        "EXPORT_JOB_PREFIX = \"export\" # エクスポートジョブのプレフィックス\n",
        "EXPORT_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/tfvision-model-export\" # エクスポートコンテナURI\n",
        "EXPORT_MACHINE_TYPE = \"n1-highmem-8\" # エクスポートのマシンタイプ\n",
        "\n",
        "# 予測定数。\n",
        "# モデルをデプロイできます\n",
        "# 事前構築済みDockerを使用:\n",
        "# 最適化されたTensorFlowランタイムDockerを使用:\n",
        "# このノートブックの例では、最適化されたTensorFlowランタイムDockerを使用しています。\n",
        "# より高速な予測を得るために、アクセラレータタイプとマシンタイプを調整できます。\n",
        "PREDICTION_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-gpu.2-11:latest\" # 予測コンテナURI\n",
        "SERVING_CONTAINER_ARGS = [\"--allow_precompilation\", \"--allow_compression\"] # サービングコンテナ引数\n",
        "PREDICTION_ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\" # 予測のアクセラレータタイプ\n",
        "PREDICTION_MACHINE_TYPE = \"n1-standard-4\" # 予測のマシンタイプ\n",
        "UPLOAD_JOB_PREFIX = \"upload\" # アップロードジョブのプレフィックス\n",
        "DEPLOY_JOB_PREFIX = \"deploy\" # デプロイジョブのプレフィックス\n",
        "\n",
        "\n",
        "# 共通関数を定義します。\n",
        "def get_job_name_with_datetime(prefix: str):\n",
        "    \"\"\"日時を含むジョブ名を取得します。\"\"\"\n",
        "    return prefix + datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def predict_custom_trained_model(\n",
        "    project: str,\n",
        "    endpoint_id: str,\n",
        "    instances: Union[Dict, List[Dict]],\n",
        "    location: str = \"us-central1\",\n",
        "):\n",
        "    \"\"\"カスタムトレーニング済みモデルを予測します。\"\"\"\n",
        "    # AI Platform サービスには、リージョンAPIエンドポイントが必要です。\n",
        "    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
        "    # リクエストの作成と送信に使用されるクライアントを初期化します。\n",
        "    # このクライアントは一度だけ作成する必要があり、複数のリクエストで再利用できます。\n",
        "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "    parameters_dict = {}\n",
        "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "    endpoint = client.endpoint_path(\n",
        "        project=project, location=location, endpoint=endpoint_id\n",
        "    )\n",
        "    response = client.predict(\n",
        "        endpoint=endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    return response.predictions, response.deployed_model_id\n",
        "\n",
        "\n",
        "def load_img(path):\n",
        "    \"\"\"画像を読み込みます。\"\"\"\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    return Image.fromarray(numpy.uint8(img)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "def display_image(image):\n",
        "    \"\"\"画像を表示します。\"\"\"\n",
        "    _ = plt.figure(figsize=(20, 15))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "def get_prediction_instances(test_filepath, new_width=-1):\n",
        "    \"\"\"予測インスタンスを取得します。\"\"\"\n",
        "    if new_width <= 0:\n",
        "        with tf.io.gfile.GFile(test_filepath, \"rb\") as input_file:\n",
        "            encoded_string = base64.b64encode(input_file.read()).decode(\"utf-8\")\n",
        "    else:\n",
        "        img = load_img(test_filepath)\n",
        "        width, height = img.size\n",
        "        print(\"元の入力画像サイズ: \", width, \" , \", height)\n",
        "        new_height = int(height * new_width / width)\n",
        "        new_img = img.resize((new_width, new_height))\n",
        "        print(\"サイズ変更後の入力画像サイズ: \", new_width, \" , \", new_height)\n",
        "        buffered = BytesIO()\n",
        "        new_img.save(buffered, format=\"JPEG\")\n",
        "        encoded_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    instances = [\n",
        "        {\n",
        "            \"encoded_image\": {\"b64\": encoded_string},\n",
        "        }\n",
        "    ]\n",
        "    return instances\n",
        "\n",
        "\n",
        "def get_label_map(label_map_yaml_filepath):\n",
        "    \"\"\"ラベルマップを取得します。\"\"\"\n",
        "    with tf.io.gfile.GFile(label_map_yaml_filepath, \"rb\") as input_file:\n",
        "        label_map = yaml.safe_load(input_file.read())\n",
        "    return label_map\n",
        "\n",
        "\n",
        "def get_best_trial(model_dir, max_trial_count, evaluation_metric):\n",
        "    \"\"\"最適な試行を取得します。\"\"\"\n",
        "    best_trial_dir = \"\"\n",
        "    best_trial_evaluation_results = {}\n",
        "    best_performance = -1\n",
        "\n",
        "    for i in range(max_trial_count):\n",
        "        current_trial = i + 1\n",
        "        current_trial_dir = os.path.join(model_dir, \"trial_\" + str(current_trial))\n",
        "        current_trial_best_ckpt_dir = os.path.join(current_trial_dir, \"best_ckpt\")\n",
        "        current_trial_best_ckpt_evaluation_filepath = os.path.join(\n",
        "            current_trial_best_ckpt_dir, \"info.json\"\n",
        "        )\n",
        "        with tf.io.gfile.GFile(current_trial_best_ckpt_evaluation_filepath, \"rb\") as f:\n",
        "            eval_metric_results = json.load(f)\n",
        "            current_performance = eval_metric_results[evaluation_metric]\n",
        "            if current_performance > best_performance:\n",
        "                best_performance = current_performance\n",
        "                best_trial_dir = current_trial_dir\n",
        "                best_trial_evaluation_results = eval_metric_results\n",
        "    return best_trial_dir, best_trial_evaluation_results\n",
        "\n",
        "\n",
        "def upload_checkpoint_to_gcs(checkpoint_url):\n",
        "    \"\"\"チェックポイントをGCSにアップロードします。\"\"\"\n",
        "    filename = os.path.basename(checkpoint_url)\n",
        "    checkpoint_name = filename.replace(\".tar.gz\", \"\")\n",
        "    print(\"チェックポイントを\", checkpoint_url, \"からダウンロードし、\", CHECKPOINT_BUCKET, \"に保存します\")\n",
        "    ! wget $checkpoint_url -O $filename\n",
        "    ! mkdir -p $checkpoint_name\n",
        "    ! tar -xvzf $filename -C $checkpoint_name\n",
        "\n",
        "    # チェックポイントへの相対パスを検索します。\n",
        "    checkpoint_path = None\n",
        "    for root, dirs, files in os.walk(checkpoint_name):\n",
        "        for file in files:\n",
        "            if file.endswith(\".index\"):\n",
        "                checkpoint_path = os.path.join(root, os.path.splitext(file)[0])\n",
        "                checkpoint_path = os.path.relpath(checkpoint_path, checkpoint_name)\n",
        "                break\n",
        "\n",
        "    ! gsutil cp -r $checkpoint_name $CHECKPOINT_BUCKET/\n",
        "    checkpoint_uri = os.path.join(CHECKPOINT_BUCKET, checkpoint_name, checkpoint_path)\n",
        "    print(\"チェックポイントが\", checkpoint_uri, \"にアップロードされました\")\n",
        "    return checkpoint_uri\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2356e904526"
      },
      "source": [
        "## 新しいモデルのトレーニング\n",
        "\n",
        "このセクションでは、以下の手順でモデルをトレーニングします。\n",
        "1. 入力データをトレーニングフォーマットに変換します。\n",
        "2. 新しいモデルをトレーニングするためのハイパーパラメータ調整ジョブを作成します。\n",
        "3. 最適なモデルを見つけてエクスポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IndQ_m6ddUEM"
      },
      "outputs": [],
      "source": [
        "# @title トレーニング用の入力データを準備する\n",
        "\n",
        "# @markdown このセクションでは、入力データをトレーニングフォーマットに変換し、指定された分割比率とシャード数でトレーニング/テスト/検証データセットに分割します。\n",
        "\n",
        "# @markdown [こちら](https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data)に記載されている形式でデータを準備し、以下のようにトレーニングフォーマットに変換します。\n",
        "# @markdown * `input_file_path`: データ準備用の入力ファイルパス。入力ファイルの例: `gs://cloud-samples-data/ai-platform/flowers/flowers.csv`\n",
        "# @markdown * `input_file_type`: 入力ファイルの種類。「csv」または「jsonl」を指定できます。\n",
        "# @markdown * `num_classes`: データセット内のクラス数。\n",
        "# @markdown * `split_ratio`: トレーニング/検証/テストに分割するデータの比率。例: 「0.8,0.1,0.1」。\n",
        "# @markdown * `num_shard`: トレーニング/検証/テストのシャード数。例: 「10,10,10」。\n",
        "\n",
        "# このジョブは、指定された分割比率とトレーニング/テスト/検証のシャード数で、入力データをトレーニングフォーマットに変換します。\n",
        "\n",
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "data_converter_job_name = get_job_name_with_datetime(\n",
        "    DATA_CONVERTER_JOB_PREFIX + \"_\" + OBJECTIVE\n",
        ")\n",
        "\n",
        "input_file_path = \"gs://cloud-samples-data/ai-platform/flowers/flowers.csv\"  # @param {type:\"string\"} {isTemplate:true}\n",
        "input_file_type = \"csv\"  # @param [\"csv\", \"jsonl\"]\n",
        "num_classes = 5  # @param {type:\"integer\"}\n",
        "split_ratio = \"0.8,0.1,0.1\"  # @param {type:\"string\"}\n",
        "num_shard = \"10,10,10\"  # @param {type:\"string\"}\n",
        "data_converter_output_dir = os.path.join(BUCKET_URI, data_converter_job_name)\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": DATA_CONVERTER_MACHINE_TYPE,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": DATA_CONVERTER_CONTAINER,\n",
        "            \"command\": [],\n",
        "            \"args\": [\n",
        "                \"--input_file_path=%s\" % input_file_path,\n",
        "                \"--input_file_type=%s\" % input_file_type,\n",
        "                \"--objective=%s\" % OBJECTIVE,\n",
        "                \"--num_shard=%s\" % num_shard,\n",
        "                \"--split_ratio=%s\" % split_ratio,\n",
        "                \"--output_dir=%s\" % data_converter_output_dir,\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "data_converter_custom_job = aiplatform.CustomJob(\n",
        "    display_name=data_converter_job_name,\n",
        "    project=PROJECT_ID,\n",
        "    worker_pool_specs=worker_pool_specs,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "data_converter_custom_job.run()\n",
        "\n",
        "input_train_data_path = os.path.join(data_converter_output_dir, \"train.tfrecord*\")\n",
        "input_validation_data_path = os.path.join(data_converter_output_dir, \"val.tfrecord*\")\n",
        "label_map_path = os.path.join(data_converter_output_dir, \"label_map.yaml\")\n",
        "print(\"input_train_data_path for training: \", input_train_data_path)\n",
        "print(\"input_validation_data_path for training: \", input_validation_data_path)\n",
        "print(\"label_map_path for prediction: \", label_map_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c3211e01b6d"
      },
      "outputs": [],
      "source": [
        "# @title ハイパーパラメータ調整を使用した Vertex AI カスタムジョブの作成と実行\n",
        "\n",
        "# @markdown このセクションでは、Vertex AI SDK を使用して、Vertex AI Model Garden トレーニング Docker でハイパーパラメータ調整ジョブを作成および実行します。\n",
        "\n",
        "# @markdown 次の実験から1つを選択します。\n",
        "# @markdown * tfhub/EfficientNetV2: `Efficientnetv2-m`\n",
        "# @markdown * tfvision/ViT: `ViT-ti16`, `ViT-s16`, `ViT-b16`, `ViT-l16`\n",
        "# @markdown * Proprietary/MaxViT: `MaxViT`\n",
        "\n",
        "# 入力トレーニングデータセットと検証データセットは、上記の「トレーニング用入力データの変換」セクションにあります。\n",
        "# 準備されたデータセットが存在する場合は設定します。\n",
        "# input_train_data_path = ''\n",
        "# input_validation_data_path = ''\n",
        "\n",
        "experiment = \"Efficientnetv2-m\"  # @param [\"Efficientnetv2-m\",\"ViT-ti16\",\"ViT-s16\",\"ViT-b16\",\"ViT-l16\", \"MaxViT\"]\n",
        "\n",
        "train_job_name = get_job_name_with_datetime(TRAINING_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "model_dir = os.path.join(BUCKET_URI, train_job_name)\n",
        "\n",
        "# ここでの引数は主にテスト用です。より良いパフォーマンスを得るためには、更新してください。\n",
        "common_args = {\n",
        "    \"input_train_data_path\": input_train_data_path,  # トレーニングデータのパス\n",
        "    \"input_validation_data_path\": input_validation_data_path,  # 検証データのパス\n",
        "    \"objective\": OBJECTIVE,  # 目的\n",
        "    \"model_dir\": model_dir,  # モデルの保存先ディレクトリ\n",
        "    \"num_classes\": num_classes,  # クラス数\n",
        "    \"global_batch_size\": 4,  # グローバルバッチサイズ\n",
        "    \"prefetch_buffer_size\": 32,  # プリフェッチバッファサイズ\n",
        "    \"train_steps\": 2000,  # トレーニングステップ数\n",
        "    \"input_size\": \"224,224\",  # 入力サイズ\n",
        "}\n",
        "\n",
        "# 実験ごとの引数。\n",
        "experiment_container_args_dict = {\n",
        "    \"Efficientnetv2-m\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"hub_model\",  # 実験名\n",
        "        },\n",
        "    ),\n",
        "    \"ViT-ti16\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"deit_imagenet_pretrain\",  # 実験名\n",
        "            \"model_name\": \"vit-ti16\",  # モデル名\n",
        "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/vit/vit-deit-imagenet-ti16.tar.gz\",  # 初期チェックポイント\n",
        "            \"input_size\": \"224,224\",  # 入力サイズ\n",
        "        },\n",
        "    ),\n",
        "    \"ViT-s16\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"deit_imagenet_pretrain\",  # 実験名\n",
        "            \"model_name\": \"vit-s16\",  # モデル名\n",
        "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/vit/vit-deit-imagenet-s16.tar.gz\",  # 初期チェックポイント\n",
        "            \"input_size\": \"224,224\",  # 入力サイズ\n",
        "        },\n",
        "    ),\n",
        "    \"ViT-b16\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"deit_imagenet_pretrain\",  # 実験名\n",
        "            \"model_name\": \"vit-b16\",  # モデル名\n",
        "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/vit/vit-deit-imagenet-b16.tar.gz\",  # 初期チェックポイント\n",
        "            \"input_size\": \"224,224\",  # 入力サイズ\n",
        "        },\n",
        "    ),\n",
        "    \"ViT-l16\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"deit_imagenet_pretrain\",  # 実験名\n",
        "            \"model_name\": \"vit-l16\",  # モデル名\n",
        "            \"init_checkpoint\": \"https://storage.googleapis.com/tf_model_garden/vision/vit/vit-deit-imagenet-l16.tar.gz\",  # 初期チェックポイント\n",
        "            \"input_size\": \"224,224\",  # 入力サイズ\n",
        "        },\n",
        "    ),\n",
        "    \"MaxViT\": dict(\n",
        "        common_args,\n",
        "        **{\n",
        "            \"experiment\": \"maxvit_imagenet\",  # 実験名\n",
        "            \"config_file\": os.path.join(CONFIG_DIR, \"maxvit_base_imagenet_gpu.yaml\"),  # 設定ファイル\n",
        "        },\n",
        "    ),\n",
        "}\n",
        "experiment_container_args = experiment_container_args_dict[experiment]\n",
        "\n",
        "# 指定されている場合は、チェックポイントを GCS バケットにコピーします。\n",
        "init_checkpoint = experiment_container_args.get(\"init_checkpoint\")\n",
        "if init_checkpoint:\n",
        "    experiment_container_args[\"init_checkpoint\"] = upload_checkpoint_to_gcs(\n",
        "        init_checkpoint\n",
        "    )\n",
        "\n",
        "# MaxViT をサポートするコンテナを使用します\n",
        "if experiment == \"MaxViT\":\n",
        "    TRAIN_CONTAINER_URI = f\"{REGION_PREFIX}-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/tfvision-oss-v2\"\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": TRAIN_MACHINE_TYPE,  # マシンタイプ\n",
        "            \"accelerator_type\": TRAIN_ACCELERATOR_TYPE,  # アクセラレータタイプ\n",
        "            # 各トレーニングジョブは TRAIN_NUM_GPU GPU を使用します。\n",
        "            \"accelerator_count\": TRAIN_NUM_GPU,  # アクセラレータ数\n",
        "        },\n",
        "        \"replica_count\": 1,  # レプリカ数\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": TRAIN_CONTAINER_URI,  # コンテナイメージURI\n",
        "            \"args\": [\n",
        "                \"--mode=train_and_eval\",  # モード\n",
        "                \"--params_override=runtime.num_gpus=%d\" % TRAIN_NUM_GPU,  # GPU数\n",
        "            ]\n",
        "            + [\"--{}={}\".format(k, v) for k, v in experiment_container_args.items()],  # 実験引数\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "metric_spec = {\"model_performance\": \"maximize\"}  # 指標仕様\n",
        "\n",
        "\n",
        "LEARNING_RATES = [5e-4, 1e-3] # 学習率\n",
        "# モデルはそれぞれの学習率で個別にトレーニングされ、最大試行回数は学習率の数です。\n",
        "MAX_TRIAL_COUNT = len(LEARNING_RATES)  # 最大試行回数\n",
        "parameter_spec = {\n",
        "    \"learning_rate\": hpt.DiscreteParameterSpec(values=LEARNING_RATES, scale=\"linear\"),  # 学習率のパラメータ仕様\n",
        "}\n",
        "\n",
        "print(worker_pool_specs, metric_spec, parameter_spec)\n",
        "\n",
        "# ハイパーパラメータジョブを実行します。\n",
        "train_custom_job = aiplatform.CustomJob(\n",
        "    display_name=train_job_name,  # 表示名\n",
        "    project=PROJECT_ID,  # プロジェクトID\n",
        "    worker_pool_specs=worker_pool_specs,  # ワーカープール仕様\n",
        "    staging_bucket=STAGING_BUCKET,  # ステージングバケット\n",
        ")\n",
        "\n",
        "train_hpt_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=train_job_name,  # 表示名\n",
        "    custom_job=train_custom_job,  # カスタムジョブ\n",
        "    metric_spec=metric_spec,  # 指標仕様\n",
        "    parameter_spec=parameter_spec,  # パラメータ仕様\n",
        "    max_trial_count=MAX_TRIAL_COUNT,  # 最大試行回数\n",
        "    parallel_trial_count=MAX_TRIAL_COUNT,  # 並列試行回数\n",
        "    project=PROJECT_ID,  # プロジェクトID\n",
        "    search_algorithm=None,  # 検索アルゴリズム\n",
        ")\n",
        "\n",
        "train_hpt_job.run()  # ジョブを実行\n",
        "\n",
        "print(\"experiment is: \", experiment)  # 実験名\n",
        "print(\"model_dir is: \", model_dir)  # モデルディレクトリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38a46cfda376"
      },
      "outputs": [],
      "source": [
        "# @title 最適なモデルをTF Saved Model形式でエクスポート\n",
        "\n",
        "# @markdown このセクションでは、最適なモデルをエクスポートします。\n",
        "\n",
        "# @markdown エクスポートされたモデルは、次のセクション「トレーニング済みモデルのテスト」でオンライン予測に使用できます。\n",
        "\n",
        "# TFチェックポイントからTF Saved Model形式にモデルをエクスポートします。\n",
        "# model_dirは上記のセクションからのものです。\n",
        "best_trial_dir, best_trial_evaluation_results = get_best_trial(\n",
        "    model_dir, MAX_TRIAL_COUNT, EVALUATION_METRIC\n",
        ")\n",
        "print(\"best_trial_dir: \", best_trial_dir)\n",
        "print(\"best_trial_evaluation_results: \", best_trial_evaluation_results)\n",
        "\n",
        "worker_pool_specs = [\n",
        "    {\n",
        "        \"machine_spec\": {\n",
        "            \"machine_type\": EXPORT_MACHINE_TYPE,\n",
        "        },\n",
        "        \"replica_count\": 1,\n",
        "        \"container_spec\": {\n",
        "            \"image_uri\": EXPORT_CONTAINER_URI,\n",
        "            \"command\": [],\n",
        "            \"args\": [\n",
        "                \"--objective=%s\" % OBJECTIVE,\n",
        "                \"--input_image_size=%s\" % experiment_container_args[\"input_size\"],\n",
        "                \"--experiment=%s\" % experiment_container_args[\"experiment\"],\n",
        "                \"--config_file=%s/params.yaml\" % best_trial_dir,\n",
        "                \"--checkpoint_path=%s/best_ckpt\" % best_trial_dir,\n",
        "                \"--export_dir=%s/best_model\" % model_dir,\n",
        "            ],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "model_export_name = get_job_name_with_datetime(EXPORT_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "model_export_custom_job = aiplatform.CustomJob(\n",
        "    display_name=model_export_name,\n",
        "    project=PROJECT_ID,\n",
        "    worker_pool_specs=worker_pool_specs,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "model_export_custom_job.run()\n",
        "\n",
        "print(\"最適なモデルは次の場所に保存されます: \", os.path.join(model_dir, \"best_model\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c68112dc90b9"
      },
      "source": [
        "## Test trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYuQowyZEtxK"
      },
      "outputs": [],
      "source": [
        "# @title モデルのアップロードとデプロイ\n",
        "\n",
        "# @markdown このセクションでは、オンライン予測のためにモデルレジストリにモデルをアップロードしてデプロイします。この例では、「新しいモデルのトレーニング」セクションからエクスポートされた最適なモデルを使用します。\n",
        "\n",
        "trained_model_dir = os.path.join(model_dir, \"best_model/saved_model\")\n",
        "upload_job_name = get_job_name_with_datetime(UPLOAD_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "\n",
        "serving_env = {\n",
        "    \"MODEL_ID\": \"tensorflow-hub-efficientnetv2\",\n",
        "    \"DEPLOY_SOURCE\": \"notebook\",\n",
        "}\n",
        "\n",
        "model = aiplatform.Model.upload(\n",
        "    display_name=upload_job_name,  # 表示名\n",
        "    artifact_uri=trained_model_dir,  # アーティファクトのURI\n",
        "    serving_container_image_uri=PREDICTION_CONTAINER_URI,  # サービングコンテナイメージのURI\n",
        "    serving_container_args=SERVING_CONTAINER_ARGS,  # サービングコンテナの引数\n",
        "    serving_container_environment_variables=serving_env,  # サービングコンテナの環境変数\n",
        ")\n",
        "\n",
        "model.wait()\n",
        "\n",
        "print(\"アップロードされたモデル名は次のとおりです:\", upload_job_name)\n",
        "\n",
        "deploy_model_name = get_job_name_with_datetime(DEPLOY_JOB_PREFIX + \"_\" + OBJECTIVE)\n",
        "print(\"デプロイされたジョブ名は次のとおりです:\", deploy_model_name)\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    deployed_model_display_name=deploy_model_name,  # デプロイされたモデルの表示名\n",
        "    machine_type=PREDICTION_MACHINE_TYPE,  # マシンタイプ\n",
        "    traffic_split={\"0\": 100},  # トラフィック分割\n",
        "    accelerator_type=PREDICTION_ACCELERATOR_TYPE,  # アクセラレータタイプ\n",
        "    accelerator_count=1,  # アクセラレータの数\n",
        "    min_replica_count=1,  # 最小レプリカ数\n",
        "    max_replica_count=1,  # 最大レプリカ数\n",
        ")\n",
        "\n",
        "endpoint_id = endpoint.name\n",
        "print(\"エンドポイントIDは次のとおりです:\", endpoint_id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbIW9me1F2RY"
      },
      "outputs": [],
      "source": [
        "# @title 予測の実行\n",
        "\n",
        "# @markdown デプロイが成功したら、オンライン予測のためにエンドポイントに画像を送信できます。\n",
        "\n",
        "# @markdown `test_filepath`：テスト画像ファイルへのGCS URI。URIは \"gs://\" で始まる必要があります。\n",
        "\n",
        "# endpoint_idは上記のセクション（「モデルのアップロードとデプロイ」）で生成されました。\n",
        "endpoint_id = endpoint.name\n",
        "\n",
        "test_filepath = \"gs://cloud-samples-data/ai-platform/flowers/roses/9423755543_edb35141a3_n.jpg\"  # @param {type:\"string\"} {isTemplate:true}\n",
        "# 入力画像が大きすぎる場合は、予測のためにサイズを変更します。\n",
        "instances = get_prediction_instances(test_filepath, new_width=1000)\n",
        "\n",
        "# ラベルマップファイルは上記のセクション（「トレーニング用の入力データの変換」）で生成されました。\n",
        "label_map = get_label_map(label_map_path)[\"label_map\"]\n",
        "\n",
        "predictions, _ = predict_custom_trained_model(\n",
        "    project=PROJECT_ID, location=REGION, endpoint_id=endpoint_id, instances=instances\n",
        ")\n",
        "\n",
        "probs = dict(predictions[0])[\"probs\"]\n",
        "max_prob = max(probs)\n",
        "max_index = probs.index(max_prob)\n",
        "print(\"テスト画像: \", test_filepath)\n",
        "print(\"最大確率: \", max_prob, \", ラベル: \", label_map[max_index])\n",
        "img = load_img(test_filepath)\n",
        "display_image(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f72e754f2802"
      },
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax6vQVZhp9pR"
      },
      "outputs": [],
      "source": [
        "# @title リソースのクリーンアップ\n",
        "\n",
        "# @markdown 実験で使用したモデルとエンドポイントを削除して、リソースをリサイクルし、\n",
        "# @markdown 不要な継続課金を回避します。\n",
        "\n",
        "try:\n",
        "    # モデルをアンデプロイし、エンドポイントを削除します。\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "    # モデルを削除します。\n",
        "    model.delete()\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "try:\n",
        "    # カスタムジョブと HPT ジョブを削除します。\n",
        "    if data_converter_custom_job.list(\n",
        "        filter=f'display_name=\"{data_converter_job_name}\"'\n",
        "    ):\n",
        "        data_converter_custom_job.delete()\n",
        "    if train_hpt_job.list(filter=f'display_name=\"{train_job_name}\"'):\n",
        "        train_hpt_job.delete()\n",
        "    if model_export_custom_job.list(filter=f'display_name=\"{model_export_name}\"'):\n",
        "        model_export_custom_job.delete()\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "# バケットを削除します。\n",
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_NAME\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_garden_tfvision_image_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}